{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import wave\n",
    "from time import time\n",
    "from bit_manipulation import lsb_deinterleave_bytes, lsb_interleave_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def em_audio(af, string, output):\n",
    "    print (\"Please wait...\")\n",
    "    waveaudio = wave.open(af, mode='rb')\n",
    "    frame_bytes = bytearray(list(waveaudio.readframes(waveaudio.getnframes())))\n",
    "    string = string + int((len(frame_bytes)-(len(string)*8*8))/8) *'#'\n",
    "    bits = list(map(int, ''.join([bin(ord(i)).lstrip('0b').rjust(8,'0') for i in string])))\n",
    "    for i, bit in enumerate(bits):\n",
    "        frame_bytes[i] = (frame_bytes[i] & 254) | bit\n",
    "    frame_modified = bytes(frame_bytes)\n",
    "    with wave.open(output, 'wb') as fd:\n",
    "        fd.setparams(waveaudio.getparams())\n",
    "        fd.writeframes(frame_modified)\n",
    "    waveaudio.close()\n",
    "    print (\"Done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_audio('demo.wav','hello world','after.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io.wavfile as wav\n",
    "from numpy.lib import stride_tricks\n",
    "\n",
    "\"\"\" short time fourier transform of audio signal \"\"\"\n",
    "def stft(sig, frameSize, overlapFac=0.5, window=np.hanning):\n",
    "    win = window(frameSize)\n",
    "    hopSize = int(frameSize - np.floor(overlapFac * frameSize))\n",
    "\n",
    "    # zeros at beginning (thus center of 1st window should be for sample nr. 0)   \n",
    "    samples = np.append(np.zeros(int(np.floor(frameSize/2.0))), sig)    \n",
    "    # cols for windowing\n",
    "    cols = np.ceil( (len(samples) - frameSize) / float(hopSize)) + 1\n",
    "    # zeros at end (thus samples can be fully covered by frames)\n",
    "    samples = np.append(samples, np.zeros(frameSize))\n",
    "\n",
    "    frames = stride_tricks.as_strided(samples, shape=(int(cols), frameSize), strides=(samples.strides[0]*hopSize, samples.strides[0])).copy()\n",
    "    frames *= win\n",
    "\n",
    "    return np.fft.rfft(frames)    \n",
    "\n",
    "\"\"\" scale frequency axis logarithmically \"\"\"    \n",
    "def logscale_spec(spec, sr=44100, factor=20.):\n",
    "    timebins, freqbins = np.shape(spec)\n",
    "\n",
    "    scale = np.linspace(0, 1, freqbins) ** factor\n",
    "    scale *= (freqbins-1)/max(scale)\n",
    "    scale = np.unique(np.round(scale))\n",
    "\n",
    "    # create spectrogram with new freq bins\n",
    "    newspec = np.complex128(np.zeros([timebins, len(scale)]))\n",
    "    for i in range(0, len(scale)):        \n",
    "        if i == len(scale)-1:\n",
    "            newspec[:,i] = np.sum(spec[:,int(scale[i]):], axis=1)\n",
    "        else:        \n",
    "            newspec[:,i] = np.sum(spec[:,int(scale[i]):int(scale[i+1])], axis=1)\n",
    "\n",
    "    # list center freq of bins\n",
    "    allfreqs = np.abs(np.fft.fftfreq(freqbins*2, 1./sr)[:freqbins+1])\n",
    "    freqs = []\n",
    "    for i in range(0, len(scale)):\n",
    "        if i == len(scale)-1:\n",
    "            freqs += [np.mean(allfreqs[int(scale[i]):])]\n",
    "        else:\n",
    "            freqs += [np.mean(allfreqs[int(scale[i]):int(scale[i+1])])]\n",
    "\n",
    "    return newspec, freqs\n",
    "\n",
    "\"\"\" plot spectrogram\"\"\"\n",
    "def plotstft(audiopath, binsize=2**10, plotpath=None, colormap=\"jet\"):\n",
    "    samplerate, samples = wav.read(audiopath)\n",
    "\n",
    "    s = stft(samples, binsize)\n",
    "\n",
    "    sshow, freq = logscale_spec(s, factor=1.0, sr=samplerate)\n",
    "\n",
    "    ims = 20.*np.log10(np.abs(sshow)/10e-6) # amplitude to decibel\n",
    "\n",
    "    timebins, freqbins = np.shape(ims)\n",
    "\n",
    "    print(\"timebins: \", timebins)\n",
    "    print(\"freqbins: \", freqbins)\n",
    "\n",
    "    plt.figure(figsize=(15, 7.5))\n",
    "    plt.imshow(np.transpose(ims), origin=\"lower\", aspect=\"auto\", cmap=colormap, interpolation=\"none\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    plt.ylabel(\"frequency (hz)\")\n",
    "    plt.xlim([0, timebins-1])\n",
    "    plt.ylim([0, freqbins])\n",
    "\n",
    "    xlocs = np.float32(np.linspace(0, timebins-1, 5))\n",
    "    plt.xticks(xlocs, [\"%.02f\" % l for l in ((xlocs*len(samples)/timebins)+(0.5*binsize))/samplerate])\n",
    "    ylocs = np.int16(np.round(np.linspace(0, freqbins-1, 10)))\n",
    "    plt.yticks(ylocs, [\"%.02f\" % freq[i] for i in ylocs])\n",
    "\n",
    "    if plotpath:\n",
    "        plt.savefig(plotpath, bbox_inches=\"tight\")\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    return ims\n",
    "\n",
    "ims = plotstft(\"test.jpg.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def make_wav(image_filename):\n",
    "    \"\"\" Make a WAV file having a spectrogram resembling an image \"\"\"\n",
    "    # Load image\n",
    "    image = mpimg.imread(image_filename)\n",
    "    image = np.sum(image, axis = 2).T[:, ::-1]\n",
    "    image = image**3 # ???\n",
    "    w, h = image.shape\n",
    "\n",
    "    # Fourier transform, normalize, remove DC bias\n",
    "    data = np.fft.irfft(image, h*2, axis=1).reshape((w*h*2))\n",
    "    data -= np.average(data)\n",
    "    data *= (2**15-1.)/np.amax(data)\n",
    "    data = array(\"h\", np.int_(data)).tostring()\n",
    "\n",
    "    # Write to disk\n",
    "    output_file = wave.open(image_filename+\".wav\", \"w\")\n",
    "    output_file.setparams((1, 2, 44100, 0, \"NONE\", \"not compressed\"))\n",
    "    output_file.writeframes(data)\n",
    "    output_file.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    my_image = \"spectrogram.png\"\n",
    "    make_wav('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_data(sound_path, file_path, output_path, num_lsb):\n",
    "    \"\"\"Hide data from the file at file_path in the sound file at sound_path\"\"\"\n",
    "    if sound_path is None:\n",
    "        raise ValueError(\"WavSteg hiding requires an input sound file path\")\n",
    "    if file_path is None:\n",
    "        raise ValueError(\"WavSteg hiding requires a secret file path\")\n",
    "    if output_path is None:\n",
    "        raise ValueError(\"WavSteg hiding requires an output sound file path\")\n",
    "\n",
    "    sound = wave.open(sound_path, \"r\")\n",
    "\n",
    "    params = sound.getparams()\n",
    "    num_channels = sound.getnchannels()\n",
    "    sample_width = sound.getsampwidth()\n",
    "    num_frames = sound.getnframes()\n",
    "    num_samples = num_frames * num_channels\n",
    "\n",
    "    # We can hide up to num_lsb bits in each sample of the sound file\n",
    "    max_bytes_to_hide = (num_samples * num_lsb) // 8\n",
    "    file_size = os.stat(file_path).st_size\n",
    "\n",
    "    print(f\"Using {num_lsb} LSBs, we can hide {max_bytes_to_hide} bytes\")\n",
    "\n",
    "    start = time()\n",
    "    sound_frames = sound.readframes(num_frames)\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        data = file.read()\n",
    "    print(\"Files read\".ljust(30) + f\" in {time() - start:.2f}s\")\n",
    "\n",
    "    if file_size > max_bytes_to_hide:\n",
    "        required_lsb = math.ceil(file_size * 8 / num_samples)\n",
    "        raise ValueError(\n",
    "            \"Input file too large to hide, \"\n",
    "            f\"requires {required_lsb} LSBs, using {num_lsb}\"\n",
    "        )\n",
    "\n",
    "    if sample_width != 1 and sample_width != 2:\n",
    "        # Python's wave module doesn't support higher sample widths\n",
    "        raise ValueError(\"File has an unsupported bit-depth\")\n",
    "\n",
    "    start = time()\n",
    "    sound_frames = lsb_interleave_bytes(\n",
    "        sound_frames, data, num_lsb, byte_depth=sample_width\n",
    "    )\n",
    "    print(f\"{file_size} bytes hidden\".ljust(30) + f\" in {time() - start:.2f}s\")\n",
    "\n",
    "    start = time()\n",
    "    sound_steg = wave.open(output_path, \"w\")\n",
    "    sound_steg.setparams(params)\n",
    "    sound_steg.writeframes(sound_frames)\n",
    "    sound_steg.close()\n",
    "    print(\"Output wav written\".ljust(30) + f\" in {time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 LSBs, we can hide 1094661 bytes\n",
      "Files read                     in 0.07s\n",
      "11 bytes hidden                in 0.02s\n",
      "Output wav written             in 0.01s\n"
     ]
    }
   ],
   "source": [
    "hide_data(\"demo.wav\",\"untitled.txt\",\"testing.wav\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_data(sound_path, output_path, num_lsb, bytes_to_recover):\n",
    "    \"\"\"Recover data from the file at sound_path to the file at output_path\"\"\"\n",
    "    if sound_path is None:\n",
    "        raise ValueError(\"WavSteg recovery requires an input sound file path\")\n",
    "    if output_path is None:\n",
    "        raise ValueError(\"WavSteg recovery requires an output file path\")\n",
    "    if bytes_to_recover is None:\n",
    "        raise ValueError(\"WavSteg recovery requires the number of bytes to recover\")\n",
    "\n",
    "    start = time()\n",
    "    sound = wave.open(sound_path, \"r\")\n",
    "\n",
    "    # num_channels = sound.getnchannels()\n",
    "    sample_width = sound.getsampwidth()\n",
    "    num_frames = sound.getnframes()\n",
    "    sound_frames = sound.readframes(num_frames)\n",
    "    prnit(\"Files read\".ljust(30) + f\" in {time() - start:.2f}s\")\n",
    "\n",
    "    if sample_width != 1 and sample_width != 2:\n",
    "        # Python's wave module doesn't support higher sample widths\n",
    "        raise ValueError(\"File has an unsupported bit-depth\")\n",
    "\n",
    "    start = time()\n",
    "    data = lsb_deinterleave_bytes(\n",
    "        sound_frames, 8 * bytes_to_recover, num_lsb, byte_depth=sample_width\n",
    "    )\n",
    "    log.debug(\n",
    "        f\"Recovered {bytes_to_recover} bytes\".ljust(30) + f\" in {time() - start:.2f}s\"\n",
    "    )\n",
    "\n",
    "    start = time()\n",
    "    output_file = open(output_path, \"wb+\")\n",
    "    output_file.write(bytes(data))\n",
    "    output_file.close()\n",
    "    log.debug(\"Written output file\".ljust(30) + f\" in {time() - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover_data(\"testing.wav\",\"output.txt\",2,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode():\n",
    "    print(\"\\nEncoding Starts..\")\n",
    "    audio = wave.open(\"sample.wav\",mode=\"rb\")\n",
    "    frame_bytes = bytearray(list(audio.readframes(audio.getnframes())))\n",
    "    string = \"Spiderman is Peter Parker\"\n",
    "    print(string)\n",
    "    string = string + int((len(frame_bytes)-(len(string)*8*8))/8) *'#'\n",
    "    bits = list(map(int, ''.join([bin(ord(i)).lstrip('0b').rjust(8,'0') for i in string])))\n",
    "    for i, bit in enumerate(bits):\n",
    "        frame_bytes[i] = (frame_bytes[i] & 254) | bit\n",
    "    frame_modified = bytes(frame_bytes)\n",
    "    for i in range(0,10):\n",
    "        print(frame_bytes[i])\n",
    "    newAudio =  wave.open('sampleStego.wav', 'wb')\n",
    "    newAudio.setparams(audio.getparams())\n",
    "    newAudio.writeframes(frame_modified)\n",
    "\n",
    "    newAudio.close()\n",
    "    audio.close()\n",
    "    print(\" |---->succesfully encoded inside sampleStego.wav\")\n",
    "\n",
    "def decode():\n",
    "    print(\"\\nDecoding Starts..\")\n",
    "    audio = wave.open(\"sampleStego.wav\", mode='rb')\n",
    "    frame_bytes = bytearray(list(audio.readframes(audio.getnframes())))\n",
    "    extracted = [frame_bytes[i] & 1 for i in range(len(frame_bytes))]\n",
    "    string = \"\".join(chr(int(\"\".join(map(str,extracted[i:i+8])),2)) for i in range(0,len(extracted),8))\n",
    "    decoded = string.split(\"###\")[0]\n",
    "    print(\"Sucessfully decoded: \"+decoded)\n",
    "    audio.close()\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
